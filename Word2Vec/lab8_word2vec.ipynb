{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction to Word Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Import necessary packages we need. \"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Simple text cleaning \"\"\"\n",
    "\n",
    "# Read stopword list\n",
    "with open('stopwords.txt') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [w.strip() for w in stopwords]\n",
    "\n",
    "# Read dictionary of abbreviation as key and its orginal form as value\n",
    "with open('abbreviations.json') as f:\n",
    "    abbr_dict = json.load(f)\n",
    "\n",
    "\"\"\" Preprocessing utility for later use. \"\"\"\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # Remove '\\n' and '\\'\n",
    "    text = text.lower().replace(\"\\\\n\", \"\").replace('\\\\', '')\n",
    "    # Replace abbreviation to its orginal form\n",
    "    for k, v in abbr_dict.items():\n",
    "        text = text.replace(k, v)\n",
    "    # Remove non-letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # Remove stop words and join the words back into one string separated by space\n",
    "    text = \" \".join([w for w in text.split() if not w in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Representation\n",
    "- Use one-hot vectors in the context of machine learning/deep learning.\n",
    "    - For example, our vocabulary is: {'dog, 'cat', 'bark', 'meow'}\n",
    "    - Then each word represents in one-hot will be:\n",
    "        - vec('dog') : [1, 0, 0, 0]\n",
    "        - vec('cat') : [0, 1, 0, 0]\n",
    "        - vec('bark'): [0, 0, 1, 0]\n",
    "        - vec('meow'): [0, 0, 0, 1]\n",
    "- Problems: \n",
    "    - Hard to measure word similarity.\n",
    "    - Cannot handle missing words.\n",
    "    - Hard to compute semantic relationships (e.g. \"I am good at NLP\" v.s. \"I am a NLP expert\")\n",
    "    - Inefficent to compute when vocabulary size is large.\n",
    "\n",
    "## Distributional Representation\n",
    "\n",
    "- Motivation: Preserve semantic information while having relatively low dimensionality for machine learning/deep learning. \n",
    "- Idea: Distributional hypothesis, \"Words that occur in similar contexts (with the same neighboring words), tend to have similar meanings.\".\n",
    "- Two main approaches: count-based model and predictive model.\n",
    "\n",
    "### Count-based Model\n",
    "- Idea: Compute the statistics of how often some word co-occurs with its neighbor words in a large text corpus, sometimes further maps these count-statistics down to a small, dense vector for each word.\n",
    "- Adavantage: Capture co-occurrence statistics of the corpus (\"global\" information).\n",
    "- Problem: Sparse, matrix is very large to compute (need a lot of memory).\n",
    "- Let's see the following simple example. We basically do the following things:\n",
    "    - Use `CountVectorizer` to build document-term matrix.\n",
    "    - Build word co-occurence matrix from document-term matrix.\n",
    "    - Each row/col of word co-occurence matrix is our word distributional representation.\n",
    "    - Measure the word similarity using cosine similarity.\n",
    "    - Visualize word vectors using SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {u'fly': 4, u'run': 6, u'dog': 3, u'cat': 2, u'meows': 5, u'sleep': 7, u'bark': 0, u'bird': 1}\n",
      "Unordered columns: [u'fly', u'run', u'dog', u'cat', u'meows', u'sleep', u'bark', u'bird']\n",
      "Ordered columns: [u'bark', u'bird', u'cat', u'dog', u'fly', u'meows', u'run', u'sleep']\n",
      "\n",
      "Document-Term Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bark</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>fly</th>\n",
       "      <th>meows</th>\n",
       "      <th>run</th>\n",
       "      <th>sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the dog run.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the cat run.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the dog sleep.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the cat sleep.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the dog bark.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the cat meows.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the bird fly.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the bird sleep.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bark  bird  cat  dog  fly  meows  run  sleep\n",
       "the dog run.        0     0    0    1    0      0    1      0\n",
       "the cat run.        0     0    1    0    0      0    1      0\n",
       "the dog sleep.      0     0    0    1    0      0    0      1\n",
       "the cat sleep.      0     0    1    0    0      0    0      1\n",
       "the dog bark.       1     0    0    1    0      0    0      0\n",
       "the cat meows.      0     0    1    0    0      1    0      0\n",
       "the bird fly.       0     1    0    0    1      0    0      0\n",
       "the bird sleep.     0     1    0    0    0      0    0      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Co-occurence Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bark</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>fly</th>\n",
       "      <th>meows</th>\n",
       "      <th>run</th>\n",
       "      <th>sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bark</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fly</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meows</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bark  bird  cat  dog  fly  meows  run  sleep\n",
       "bark      1     0    0    1    0      0    0      0\n",
       "bird      0     1    0    0    1      0    0      1\n",
       "cat       0     0    1    0    0      1    1      1\n",
       "dog       1     0    0    1    0      0    1      1\n",
       "fly       0     1    0    0    1      0    0      0\n",
       "meows     0     0    1    0    0      1    0      0\n",
       "run       0     0    1    1    0      0    1      0\n",
       "sleep     0     1    1    1    0      0    0      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Word-to-ID dictionary'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{u'bark': 0,\n",
       " u'bird': 1,\n",
       " u'cat': 2,\n",
       " u'dog': 3,\n",
       " u'fly': 4,\n",
       " u'meows': 5,\n",
       " u'run': 6,\n",
       " u'sleep': 7}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ID-to-Word dictionary'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: u'bark',\n",
       " 1: u'bird',\n",
       " 2: u'cat',\n",
       " 3: u'dog',\n",
       " 4: u'fly',\n",
       " 5: u'meows',\n",
       " 6: u'run',\n",
       " 7: u'sleep'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog vector: [1 0 0 1 0 0 1 1]\n",
      "cat vector: [0 0 1 0 0 1 1 1]\n",
      "bird vector: [0 1 0 0 1 0 0 1]\n",
      "bark vector: [1 0 0 1 0 0 0 0]\n",
      "\n",
      "dog v.s. cat: 0.5\n",
      "dog v.s. bird: 0.288675134595\n",
      "dog v.s. bark: 0.707106781187\n",
      "cat v.s. bark: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noM0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5bceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume this is our data.\n",
    "documents = [\n",
    "    'the dog run.',\n",
    "    'the cat run.',\n",
    "    'the dog sleep.',\n",
    "    'the cat sleep.',\n",
    "    'the dog bark.',\n",
    "    'the cat meows.',\n",
    "    'the bird fly.',\n",
    "    'the bird sleep.'\n",
    "]\n",
    "\n",
    "# Contruct document-term matrix\n",
    "vectorizer = CountVectorizer(preprocessor=clean_text, analyzer='word', ngram_range=(1, 1))\n",
    "\n",
    "# Or... you can try `TfidfVectorizer`\n",
    "# vectorizer = TfidfVectorizer(preprocessor=clean_text, analyzer='word', ngram_range=(1, 1))\n",
    "\n",
    "document_term_matrix = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "# Contruct word-occurence matrix from document-term matrix\n",
    "word_cooccurence_matrix = np.dot(document_term_matrix.T, document_term_matrix)\n",
    "np.fill_diagonal(word_cooccurence_matrix, 1)\n",
    "\n",
    "# Print mapping of term and feature index\n",
    "print('Vocabulary: {}'.format(vectorizer.vocabulary_))\n",
    "\n",
    "# We need to sort key by its index in order to visualize feature index in correct order.\n",
    "ordered_columns = []\n",
    "for col, index in vectorizer.vocabulary_.items():\n",
    "    ordered_columns.append((col, index))\n",
    "ordered_columns.sort(key=lambda x: x[1])\n",
    "ordered_columns = [col for col, index in ordered_columns]\n",
    "\n",
    "# If you iterate dictionary, it won't preserve the order\n",
    "unordered_columns = [col for col, index in vectorizer.vocabulary_.items()]\n",
    "\n",
    "print('Unordered columns: {}'.format(unordered_columns))\n",
    "print('Ordered columns: {}'.format(ordered_columns))\n",
    "\n",
    "# Visualize our document-term matrix\n",
    "print('\\nDocument-Term Matrix:')\n",
    "display(pd.DataFrame(document_term_matrix, index=documents, columns=ordered_columns))\n",
    "# Visualize our word-occurence matrix\n",
    "print('\\nWord Co-occurence Matrix:')\n",
    "display(pd.DataFrame(word_cooccurence_matrix, index=ordered_columns, columns=ordered_columns))\n",
    "\n",
    "word2id = vectorizer.vocabulary_\n",
    "id2word = {x[1]: x[0] for x in word2id.items()}\n",
    "\n",
    "display('Word-to-ID dictionary')\n",
    "display(word2id)\n",
    "display('ID-to-Word dictionary')\n",
    "display(id2word)\n",
    "\n",
    "vector_dog = word_cooccurence_matrix[word2id['dog']]\n",
    "vector_cat = word_cooccurence_matrix[word2id['cat']]\n",
    "vector_bird = word_cooccurence_matrix[word2id['bird']]\n",
    "vector_bark = word_cooccurence_matrix[word2id['bark']]\n",
    "\n",
    "print('dog vector: {}'.format(vector_dog))\n",
    "print('cat vector: {}'.format(vector_cat))\n",
    "print('bird vector: {}'.format(vector_bird))\n",
    "print('bark vector: {}\\n'.format(vector_bark))\n",
    "\n",
    "print('dog v.s. cat: {}'.format(1 - cosine(vector_dog, vector_cat)))\n",
    "print('dog v.s. bird: {}'.format(1 - cosine(vector_dog, vector_bird)))\n",
    "print('dog v.s. bark: {}'.format(1 - cosine(vector_dog, vector_bark)))\n",
    "print('cat v.s. bark: {}'.format(1 - cosine(vector_cat, vector_bark)))\n",
    "\n",
    "# Visualize word vectors using SVD.\n",
    "# Hint: Using TF-IDF will looks better.\n",
    "fig = plt.figure()\n",
    "U, sigma, Vh = np.linalg.svd(word_cooccurence_matrix)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis([-1, 1, -1, 1])\n",
    "for i in id2word:\n",
    "    ax.text(U[i, 0], U[i, 1], id2word[i], alpha=0.5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model\n",
    "- Idea: Directly try to predict a word from its neighbors in terms of learned small, dense embedding vectors (considered parameters of the model).\n",
    "- Word2vec: A neural-based(shallow neural network) efficient model (Widely used nowadays)\n",
    "- Adavantage: Scanning context windows across the entire corpus needs less memory than count-based model.\n",
    "- Problem: Need more time to compute.\n",
    "\n",
    "## Word2vec\n",
    "- Two different objectives:\n",
    "    - *Continuous Bag of Words (CBOW)*: Predict target word from context words.\n",
    "    - *Skip-grams*: Predict context words from target word.\n",
    "- Two efficient training algorithms: *Negative Sampling* and *Hierarchical Softmax*.\n",
    "![CBOW-SG](img/cbow-sg.png)\n",
    "- We only introduce *Skip-grams* and *Negative Sampling* here.\n",
    "\n",
    "### Skip-gram\n",
    "- Objective: Given a target word, maximize the probability of the context word (Maximum likelihood estimation). For mathimatical convenience, it's equivalent to **minimizing negative log probability** since product becomes sum.\n",
    "- Maximizing the objective $J(\\theta) = \\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m, j \\neq 0} p(w_{t+j} | w_t ; \\theta)$ turns to minimizing $J'(\\theta) = -\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m, j \\neq 0} \\log p(w_{t+j} | w_t ; \\theta)$.\n",
    "- $t$ denotes the index of center word, $m$ denotes window size.\n",
    "- With probability defined as: $p(o|c) = \\frac{exp(u_o^T v_c)}{\\sum_{w=1}^W exp(u_w^T v_c)}$, where $o$ denotes output word index, $c$ denotes center(target) word index and $W$ is number of vocabulary.\n",
    "- Dot product $u^T v = u \\cdot v$: Bigger if $u$ and $v$ is similar!\n",
    "- Softmax $\\frac{exp(z_i)}{\\sum_j exp(z_j)}$: $exp(z_i)$ yields positive numbers; dividing $\\sum_j exp(z_j)$ normalizes the output to probability distribution.\n",
    "- Compute gradients of $\\theta$ w.r.t $v_c$ and update $\\theta$ by sochastic gradient descent: $\\theta^{new} = \\theta^{old} - \\alpha\\frac{\\partial}{\\partial\\theta^{old}}J'(\\theta)$, where $\\alpha$ is *learning rate*.\n",
    "- Problem of softmax function: For each training step, we need to do the gigantic sum ($\\sum_{w=1}^W exp(u_w^T v_c)$ term in softmax), which is very computationally expensive.\n",
    "![SG](img/sg.png)\n",
    "\n",
    "### Negative Sampling (Simplified Version of Noise Contrastive Estimation; NCE)\n",
    "- Idea: Instead of doing giganic sum in softmax function, we turn our previous objective into **maximizing probability of true pair (center word paired with word in its context window)** and **minimizing noise pairs (center word paired with a random word)**\n",
    "- New objective is defined as: $\\log\\sigma(u_o^T v_c) + \\sum_{i=1}^k \\mathbb{E}_{j~P(w)}[log \\sigma(-u_j^T v_c)]$, where there are $k$ negative samples for each data sample. $k$ in the range 5–20 are useful for small training datasets, while for large datasets the $k$ can be as\n",
    "small as 2–5.\n",
    "- $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ maps $x$ to 0~1, which mimics the measurement of probability.\n",
    "\n",
    "## More popular word/sentence embeddings to use:\n",
    "- [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)\n",
    "- [FastText by Facebook](https://github.com/facebookresearch/fastText)\n",
    "- [Paragraph2vec/Doc2vec (Extenstion of word2vec)](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "- [Skip-Thought Vectors](https://github.com/ryankiros/skip-thoughts)\n",
    "- [Sense2Vec](https://github.com/explosion/sense2vec)\n",
    "- https://github.com/Hironsan/awesome-embedding-models\n",
    "\n",
    "## Relative papers:\n",
    "- [Don’t count, predict! A systematic comparison ofcontext-counting vs. context-predicting semantic vectors](http://clic.cimec.unitn.it/marco/publications/acl2014/baroni-etal-countpredict-acl2014.pdf)\n",
    "- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "- [Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "- [word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722v1.pdf)\n",
    "- [Neural Word Embedding as Implicit Matrix Factorization](https://arxiv.org/pdf/1402.3722v1.pdf)\n",
    "- [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)\n",
    "- [Improving Distributional Similarity with Lessons Learned from Word Embeddings](http://www.aclweb.org/anthology/Q15-1016)\n",
    "- [Evaluation methods for unsupervised word embeddings](http://www.aclweb.org/anthology/D15-1036)\n",
    "\n",
    "## Reference:\n",
    "The above content is covered in more detail on [Standford Cs224d Deep learning for NLP](http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input for word2vec:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[u'dog', u'run'],\n",
       " [u'cat', u'run'],\n",
       " [u'dog', u'sleep'],\n",
       " [u'cat', u'sleep'],\n",
       " [u'dog', u'bark'],\n",
       " [u'cat', u'meows'],\n",
       " [u'bird', u'fly'],\n",
       " [u'bird', u'sleep']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2vec ...\n",
      "\n",
      "Attributes in word2vec model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.025,\n",
       " 'batch_words': 10000,\n",
       " 'cbow_mean': 1,\n",
       " 'corpus_count': 8,\n",
       " 'cum_table': array([ 370789616,  741579233, 1112368849, 1385932959, 1659497069,\n",
       "        1822159261, 1984821454, 2147483647], dtype=uint32),\n",
       " 'hashfxn': <function hash>,\n",
       " 'hs': 0,\n",
       " 'index2word': [u'dog',\n",
       "  u'cat',\n",
       "  u'sleep',\n",
       "  u'run',\n",
       "  u'bird',\n",
       "  u'fly',\n",
       "  u'meows',\n",
       "  u'bark'],\n",
       " 'iter': 5,\n",
       " 'layer1_size': 2,\n",
       " 'max_vocab_size': None,\n",
       " 'min_alpha': 0.0001,\n",
       " 'min_count': 1,\n",
       " 'negative': 5,\n",
       " 'null_word': 0,\n",
       " 'random': <mtrand.RandomState at 0x1eacadc8>,\n",
       " 'raw_vocab': defaultdict(int, {}),\n",
       " 'sample': 0.001,\n",
       " 'seed': 1,\n",
       " 'sg': 1,\n",
       " 'sorted_vocab': 1,\n",
       " 'syn0': array([[ 0.18050483,  0.09861663],\n",
       "        [ 0.08727898, -0.03335002],\n",
       "        [-0.04235737, -0.19968219],\n",
       "        [ 0.14245959, -0.05026545],\n",
       "        [-0.14987873, -0.19993468],\n",
       "        [-0.18128334,  0.22444636],\n",
       "        [ 0.04830213, -0.23783977],\n",
       "        [-0.20259045,  0.24417111]], dtype=float32),\n",
       " 'syn0_lockf': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32),\n",
       " 'syn0norm': None,\n",
       " 'syn1neg': array([[ 0.        ,  0.        ],\n",
       "        [ 0.00072447, -0.00022407],\n",
       "        [-0.00457837,  0.00164679],\n",
       "        [ 0.00110354, -0.00042169],\n",
       "        [-0.00282994,  0.00102987],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [-0.00107737,  0.00041169]], dtype=float32),\n",
       " 'total_train_time': 0.0009988387248682784,\n",
       " 'train_count': 1,\n",
       " 'vector_size': 2,\n",
       " 'vocab': {u'bark': <gensim.models.word2vec.Vocab at 0x1eaeb240>,\n",
       "  u'bird': <gensim.models.word2vec.Vocab at 0x1eaeb2b0>,\n",
       "  u'cat': <gensim.models.word2vec.Vocab at 0x1eaeb198>,\n",
       "  u'dog': <gensim.models.word2vec.Vocab at 0x1eab0e48>,\n",
       "  u'fly': <gensim.models.word2vec.Vocab at 0x1eab0710>,\n",
       "  u'meows': <gensim.models.word2vec.Vocab at 0x1eaeb278>,\n",
       "  u'run': <gensim.models.word2vec.Vocab at 0x1eab0ef0>,\n",
       "  u'sleep': <gensim.models.word2vec.Vocab at 0x1eaeb2e8>},\n",
       " 'window': 3,\n",
       " 'workers': 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD7CAYAAACPDORaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1+wSCfWUrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x48b1c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume this is our data.\n",
    "documents = [\n",
    "    'the dog run.',\n",
    "    'the cat run.',\n",
    "    'the dog sleep.',\n",
    "    'the cat sleep.',\n",
    "    'the dog bark.',\n",
    "    'the cat meows.',\n",
    "    'the bird fly.',\n",
    "    'the bird sleep.'\n",
    "]\n",
    "\n",
    "# Clean text.\n",
    "documents = [clean_text(doc) for doc in documents]\n",
    "# Prepare input format for training word2vec.\n",
    "documents = [doc.split() for doc in documents]\n",
    "print('Input for word2vec:')\n",
    "display(documents)\n",
    "\n",
    "# Start to train word2vec.\n",
    "\"\"\"\n",
    "    @param `sg`: sg defines the training algorithm (skip-gram). By default (sg=0), CBOW is used. Otherwise (sg=1).\n",
    "    @param `size`: number of dimension of the feature vectors.\n",
    "    @param `window`: maximum distance between the current and predicted word within a sentence.\n",
    "    @param `min_count`: ignore all words with total frequency lower than this.\n",
    "    @param `negative`: Specifies how many “noise words” should be drawn (usually between 5-20). (Default=5).\n",
    "                       5–20 are useful for small training datasets, while for large datasets the k can be as\n",
    "                       small as 2–5\n",
    "    More detail on: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\"\"\"\n",
    "print('Training word2vec ...\\n')\n",
    "model_w2v = gensim.models.Word2Vec(documents, sg=1, size=2, window=3, min_count=1, negative=5)\n",
    "\n",
    "print('Attributes in word2vec model:')\n",
    "display(vars(model_w2v))\n",
    "\n",
    "# Visualize word vectors.\n",
    "min_x = np.min(model_w2v.syn0[:, 0]) - 0.1\n",
    "max_x = np.max(model_w2v.syn0[:, 0]) + 0.1\n",
    "min_y = np.min(model_w2v.syn0[:, 1]) - 0.1\n",
    "max_y = np.max(model_w2v.syn0[:, 1]) + 0.1\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis([min_x, max_x, min_y, max_y])\n",
    "for word in model_w2v.index2word:\n",
    "    vec = model_w2v[word]\n",
    "    ax.text(vec[0], vec[1], word, alpha=0.5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word to \"dog\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'run', 0.6680361032485962),\n",
       " (u'cat', 0.6486285328865051),\n",
       " (u'fly', -0.17842534184455872),\n",
       " (u'bark', -0.19137904047966003),\n",
       " (u'meows', -0.2952004671096802)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word to \"cat\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'run', 0.9996675848960876),\n",
       " (u'dog', 0.6486285328865051),\n",
       " (u'meows', 0.5357112288475037),\n",
       " (u'sleep', 0.15533089637756348),\n",
       " (u'bird', -0.27470389008522034)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word to \"bird\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'sleep', 0.9071882963180542),\n",
       " (u'meows', 0.6647541522979736),\n",
       " (u'bark', -0.23277723789215088),\n",
       " (u'fly', -0.2455756664276123),\n",
       " (u'cat', -0.27470389008522034)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can use `most_similar()` to explore the top-5 similar words.\n",
    "# Cosine similarity has a range of [-1, 1]\n",
    "# You could interpret negative scores as \"opposite meaning\".\n",
    "print('Most similar word to \"dog\":')\n",
    "display(model_w2v.most_similar('dog', topn=5))\n",
    "\n",
    "print('Most similar word to \"cat\":')\n",
    "display(model_w2v.most_similar('cat', topn=5))\n",
    "\n",
    "print('Most similar word to \"bird\":')\n",
    "display(model_w2v.most_similar('bird', topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Revisit Movie Review Sentiment Classifcation: Use Word2vec!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our movie review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_path = 'movie_review/'\n",
    "dataset = load_files(container_path=folder_path, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target_names', 'data', 'target', 'DESCR', 'filenames']\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(2000L,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Print some information about the dataset \"\"\"\n",
    "print(dataset.keys())\n",
    "print(dataset.target)\n",
    "print(dataset.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn\\'t snag this one correctly . \\nthey seem to have taken this pretty neat concept , but executed it terribly . \\nso what are the problems with the movie ? \\nwell , its main problem is that it\\'s simply too jumbled . \\nit starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what\\'s going on . \\nthere are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \\nnow i personally don\\'t mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film\\'s biggest problem . \\nit\\'s obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \\nand do they make things entertaining , thrilling or even engaging , in the meantime ? \\nnot really . \\nthe sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn\\'t the make the film all that more entertaining . \\ni guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \\ni mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \\nokay , we get it . . . there \\nare people chasing her and we don\\'t know who they are . \\ndo we really need to see it over and over again ? \\nhow about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \\napparently , the studio took this film away from its director and chopped it up themselves , and it shows . \\nthere might\\'ve been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \\nthe actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \\nbut my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character\\'s unraveling . \\noverall , the film doesn\\'t stick because it doesn\\'t entertain , it\\'s confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \\noh , and by the way , this is not a horror or teen slasher flick . . . it\\'s \\njust packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \\nit also wrapped production two years ago and has been sitting on the shelves ever since . \\nwhatever . . . skip \\nit ! \\nwhere\\'s joblo coming from ? \\na nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Uncleaned data \"\"\"\n",
    "dataset.data[0] # Print one of all movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do classification with word2vec!\n",
    "This is just a example of using TF-IDF features as model input.\n",
    "\n",
    "Please train your own word2vec model on the movie review dataset,\n",
    "and use word2vec features as model input.\n",
    "\n",
    "Try to tweek word2vec hyper-parameters to get good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86       259\n",
      "          1       0.84      0.87      0.85       241\n",
      "\n",
      "avg / total       0.86      0.86      0.86       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature transform\n",
    "vectorizer = TfidfVectorizer(preprocessor=clean_text, analyzer='word', ngram_range=(1, 1))\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "y = dataset.target\n",
    "\n",
    "# Split training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=None)\n",
    "\n",
    "# Perform classification with linear SVM\n",
    "svc = LinearSVC(C=1.0, max_iter=10000)\n",
    "svc = svc.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = svc.predict(X=X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37685826,  0.06033698, -0.24850231,  0.15766107, -0.08450709,\n",
       "        0.32412264, -0.11311457, -0.14899988, -0.16866352, -0.08493064,\n",
       "        0.47031724, -0.6816324 , -0.02698175, -0.47675958,  0.13052413,\n",
       "        0.01077058, -0.24178688, -0.40936303,  0.19377889,  0.22782187,\n",
       "       -0.15980528, -0.19688235,  0.50443721, -0.14058986,  0.37168491,\n",
       "        0.26178017, -0.37566543,  0.08670595,  0.13668872, -0.4738847 ,\n",
       "       -0.3380931 ,  0.04142014, -0.75335473, -0.09258734, -0.18168569,\n",
       "       -0.12377918, -0.28688344, -0.21622771,  0.22342014, -0.23962077,\n",
       "       -0.51334292,  0.16873397,  0.00434067, -0.24235821, -0.21819264,\n",
       "        0.16241951,  0.0137586 , -0.34996718,  0.13646173,  0.23357682], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = dataset.data\n",
    "\n",
    "# Clean text.\n",
    "documents = [clean_text(doc) for doc in documents]\n",
    "# Prepare input format for training word2vec.\n",
    "documents = [doc.split() for doc in documents]\n",
    "model_w2v = gensim.models.Word2Vec(documents, sg=5, size=50, window=10, min_count=5, negative=5)\n",
    "model_w2v[\"dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using average word2vec to represent a article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_doc2vec = []\n",
    "documents_cleaned = [clean_text(doc) for doc in documents]\n",
    "for article in documents_cleaned:\n",
    "    article_vector = []\n",
    "    for word in article.split():\n",
    "        try:\n",
    "            article_vector.append(model_w2v[word])\n",
    "        except:\n",
    "            article_vector.append(np.random.rand(50))\n",
    "    average_doc2vec.append(np.array(article_vector).mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.73      0.71       255\n",
      "          1       0.70      0.66      0.68       245\n",
      "\n",
      "avg / total       0.69      0.69      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_doc2vec\n",
    "y = dataset.target\n",
    "\n",
    "# Split training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=None)\n",
    "\n",
    "# Perform classification with linear SVM\n",
    "svc = LinearSVC(C=1, max_iter=10000)\n",
    "svc = svc.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = svc.predict(X=X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus:  Perform complete experiment on word2vec weighted by TF-IDF, GloVe or other embeddings is encouraged!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using GloVe 100 dim\n",
    "with open('C:/Users/tsunh/Downloads/glove.6B/glove.6B.200d.txt') as f:\n",
    "    glove100 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the -0.071549 0.093459 0.023738 -0.090339 0.056123 0.32547 -0.39796 -0.092139 0.061181 -0.1895 0.13061 0.14349 0.011479 0.38158 0.5403 -0.14088 0.24315 0.23036 -0.55339 0.048154 0.45662 3.2338 0.020199 0.049019 -0.014132 0.076017 -0.11527 0.2006 -0.077657 0.24328 0.16368 -0.34118 -0.06607 0.10152 0.038232 -0.17668 -0.88153 -0.33895 -0.035481 -0.55095 -0.016899 -0.43982 0.039004 0.40447 -0.2588 0.64594 0.26641 0.28009 -0.024625 0.63302 -0.317 0.10271 0.30886 0.097792 -0.38227 0.086552 0.047075 0.23511 -0.32127 -0.28538 0.1667 -0.0049707 -0.62714 -0.24904 0.29713 0.14379 -0.12325 -0.058178 -0.001029 -0.082126 0.36935 -0.00058442 0.34286 0.28426 -0.068599 0.65747 -0.029087 0.16184 0.073672 -0.30343 0.095733 -0.5286 -0.22898 0.064079 0.015218 0.34921 -0.4396 -0.43983 0.77515 -0.87767 -0.087504 0.39598 0.62362 -0.26211 -0.30539 -0.022964 0.30567 0.06766 0.15383 -0.11211 -0.09154 0.082562 0.16897 -0.032952 -0.28775 -0.2232 -0.090426 1.2407 -0.18244 -0.0075219 -0.041388 -0.011083 0.078186 0.38511 0.23334 0.14414 -0.0009107 -0.26388 -0.20481 0.10099 0.14076 0.28834 -0.045429 0.37247 0.13645 -0.67457 0.22786 0.12599 0.029091 0.030428 -0.13028 0.19408 0.49014 -0.39121 -0.075952 0.074731 0.18902 -0.16922 -0.26019 -0.039771 -0.24153 0.10875 0.30434 0.036009 1.4264 0.12759 -0.073811 -0.20418 0.0080016 0.15381 0.20223 0.28274 0.096206 -0.33634 0.50983 0.32625 -0.26535 0.374 -0.30388 -0.40033 -0.04291 -0.067897 -0.29332 0.10978 -0.045365 0.23222 -0.31134 -0.28983 -0.66687 0.53097 0.19461 0.3667 0.26185 -0.65187 0.10266 0.11363 -0.12953 -0.68246 -0.18751 0.1476 1.0765 -0.22908 -0.0093435 -0.20651 -0.35225 -0.2672 -0.0034307 0.25906 0.21759 0.66158 0.1218 0.19957 -0.20303 0.34474 -0.24328 0.13139 -0.0088767 0.33617 0.030591 0.25577'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove100 = glove100.split(\"\\n\")\n",
    "glove100[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "glove_dict = defaultdict(list)\n",
    "for i in glove100:\n",
    "    try:\n",
    "        sp = i.split()\n",
    "        vector = []\n",
    "        for strin in sp[1:101]:\n",
    "            vector.append(np.float32(strin))\n",
    "        \n",
    "        glove_dict[sp[0]] = vector\n",
    "    except:\n",
    "        sp = i.split()\n",
    "        print sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_doc2vec_glove = []\n",
    "documents_cleaned = [clean_text(doc) for doc in documents]\n",
    "for article in documents_cleaned:\n",
    "    article_vector = []\n",
    "    for word in article.split():\n",
    "        if np.array(glove_dict[word]) != []:\n",
    "            article_vector.append(np.array(glove_dict[word]))\n",
    "    average_doc2vec_glove.append(np.array(article_vector).mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = average_doc2vec_glove\n",
    "y = dataset.target\n",
    "\n",
    "# Split training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=None)\n",
    "\n",
    "# Perform classification with linear SVM\n",
    "svc = LinearSVC(C=1, max_iter=10000)\n",
    "svc = svc.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = svc.predict(X=X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print type(model_w2v[\"word\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'float'>\n"
     ]
    }
   ],
   "source": [
    "print type(glove_dict[\"word\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in article_vector:\n",
    "    if len(i) != 100:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
