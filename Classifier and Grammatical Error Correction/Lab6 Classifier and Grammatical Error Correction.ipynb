{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier and Grammatical Error Correction 102034038 湯忠憲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature extraction function\n",
    "def gen_feature_set(tags, offset,words,tag_list, phrases):\n",
    "    def tags_to_word_pos(tags):\n",
    "        return \" \".join((tag[0] + \"_\" + tag[1] for tag in tags))\n",
    "\n",
    "    features = {}\n",
    "    ta_offset = offset -1\n",
    "    features['TGLR'] = tags_to_word_pos([tags[ta_offset - 1], tags[ta_offset + 1]]) if 0 < ta_offset < len(tags) - 1 else ''\n",
    "    features['TGL'] = tags_to_word_pos([tags[ta_offset - 2], tags[ta_offset - 1]]) if 1 < ta_offset else ''\n",
    "    features['TGR'] = tags_to_word_pos([tags[ta_offset + 1], tags[ta_offset + 2]]) if ta_offset < len(tags) - 2 else ''\n",
    "    features['BGL'] = tags_to_word_pos([tags[ta_offset - 1]]) if 0 < ta_offset else ''\n",
    "    features['BGR'] = tags_to_word_pos([tags[ta_offset + 1]]) if ta_offset < len(tags) - 1 else ''\n",
    "    #robust feature\n",
    "    features[\"Wrong_word\"] = words[ta_offset]\n",
    "    features[\"Wrong_tag\"] = tag_list[ta_offset]\n",
    "    \n",
    "    headword_pos = \"\"\n",
    "    fh_word = \"\"\n",
    "    fh_tag = \"\"\n",
    "    fp = \"\"\n",
    "    for k, ph in enumerate(phrases[offset:]):\n",
    "        if ph.startswith(\"I\"):\n",
    "            headword_pos = words[k+offset]+\"_\"+tag_list[k+offset]\n",
    "            fh_word = words[k+offset]\n",
    "            fh_tag = tag_list[k+offset]\n",
    "            fp = \" \".join((words[b]+\"_\"+tag_list[b] for b in range(offset,offset+k+1)))\n",
    "            break\n",
    "    features[\"FH\"] = headword_pos\n",
    "    features[\"FHword\"] = fh_word\n",
    "    features[\"FHtag\"] = fh_tag\n",
    "    features[\"FP\"] = fp\n",
    "    phr_pre = \"\"\n",
    "    for p, ph in enumerate(reversed(phrases[:offset-1])):\n",
    "        if ph.startswith(\"B\"):\n",
    "            phr_pre = ph[-2:]\n",
    "            break\n",
    "    pv=\"\"\n",
    "    pv_tag=\"\"\n",
    "    for h, tag in enumerate(reversed(tag_list[:offset-1])):\n",
    "        if tag.startswith(\"V\"):\n",
    "            pv= words[offset-h-2]+\"_\"+tag_list[offset-h-2]\n",
    "            pv_tag = tag_list[offset -h -2]\n",
    "            break\n",
    "    features[\"pv\"] = pv\n",
    "    features[\"pv_tag\"] = pv_tag\n",
    "    features[\"PHR_pre\"] = phr_pre\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a feature generator, I implement 12 features from Table 1. Besides, I recorded the original **wrong word** and **PoS tags** as features and found out that they're robust !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "\n",
    "\n",
    "corrections = list(open('wiki.prep.corrections.clean.100k'))\n",
    "data = list(open(\"wiki.prep.sents.clean.genia.100k\"))\n",
    "\n",
    "size = len(data)\n",
    "#split data\n",
    "train_data = data[:-(size//10)]\n",
    "test_data = data[-(size//10):]\n",
    "train_correction = corrections[:-(size//10)]\n",
    "test_correction = corrections[-(size//10):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', '1927', ',', 'while', 'work', 'for', 'Bell', 'Labs', ',', 'Davisson', 'and', 'Lester', 'Germer', 'perform', 'an', 'experiment', 'show', 'that', 'electron', 'be', 'diffract', 'from', 'the', 'surface', 'of', 'a', 'crystal', 'of', 'nickel', '.'] 30\n",
      "['IN', 'CD', ',', 'IN', 'VBG', 'IN', 'NNP', 'NNP', ',', 'NNP', 'CC', 'NNP', 'NNP', 'VBD', 'DT', 'NN', 'VBG', 'IN', 'NNS', 'VBD', 'VBN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NN', '.'] 30\n",
      "['B-PP', 'B-NP', 'O', 'B-SBAR', 'B-VP', 'B-PP', 'B-NP', 'I-NP', 'O', 'B-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'O'] 30\n",
      "wrong word: from\n",
      "answer: at\n",
      "phrase: B-PP\n",
      "surface_NN\n",
      "following range [22, 23]\n",
      "the_DT surface_NN\n",
      "i= 1\n",
      "ph= B-VP\n",
      "be_VBD VP\n",
      "h= 0\n",
      "diffract_VBN\n"
     ]
    }
   ],
   "source": [
    "#feature extraction test\n",
    "\n",
    "index = 1\n",
    "lines = train_data[index].split(\"\\t\")\n",
    "words = lines[1].split()\n",
    "print words,len(words)\n",
    "tags = lines[2].split()\n",
    "print tags,len(tags)\n",
    "phrases = lines[3].split()\n",
    "print phrases,len(phrases)\n",
    "input_tags = [(words[i],tags[i],phrases[i]) for i in range(len(tags))]\n",
    "offset = int(train_correction[index].split(\"\\t\")[0])\n",
    "label = train_correction[index].split(\"\\t\")[3]\n",
    "\n",
    "print \"wrong word:\",words[offset-1]\n",
    "print \"answer:\", label\n",
    "print \"phrase:\", phrases[offset-1]\n",
    "for i, ph in enumerate(phrases[offset:]):\n",
    "    if ph.startswith(\"I\"):\n",
    "        print words[i+offset]+\"_\"+tags[i+offset]\n",
    "        print \"following range\",range(offset, offset+i+1)\n",
    "        print \" \".join((words[b]+\"_\"+tags[b] for b in range(offset,offset+i+1)))\n",
    "        break\n",
    "for i, ph in enumerate(reversed(phrases[:offset-1])):\n",
    "    if ph.startswith(\"B\"):\n",
    "        print \"i=\",i\n",
    "        print \"ph=\", ph\n",
    "        print words[offset-i-2]+\"_\"+tags[offset-i-2],ph[-2:]\n",
    "        break\n",
    "for h, tag in enumerate(reversed(tags[:offset-1])):\n",
    "    if tag.startswith(\"V\"):\n",
    "        print \"h=\",h\n",
    "        print words[offset-h-2]+\"_\"+tags[offset-h-2]\n",
    "        break\n",
    "#print input_tags\n",
    "#gen_feature_set(input_tags,offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform the raw data to feature-answer pairs\n",
    "\n",
    "def data_conversion(data_input,correction):\n",
    "    featuresets = []\n",
    "    for i in range(len(data_input)):\n",
    "        lines = data_input[i].split(\"\\t\")\n",
    "        words = lines[1].split()\n",
    "        tags = lines[2].split()\n",
    "        phrases = lines[3].split()\n",
    "        input_tags = [(words[j],tags[j],phrases[j]) for j in range(len(tags))]\n",
    "        offset = int(correction[i].split(\"\\t\")[0])\n",
    "        label = correction[i].split(\"\\t\")[3].lower() #lower the answer to reduce number of class\n",
    "        featuresets.append((gen_feature_set(input_tags,offset,words,tags,phrases),label))\n",
    "    return featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainData = data_conversion(train_data,train_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'BGL': 'last_JJ',\n",
       "   'BGR': 'a_DT',\n",
       "   'FH': 'boot_NN',\n",
       "   'FHtag': 'NN',\n",
       "   'FHword': 'boot',\n",
       "   'FP': 'a_DT boot_NN',\n",
       "   'PHR_pre': 'JP',\n",
       "   'TGL': 'style_NN last_JJ',\n",
       "   'TGLR': 'last_JJ a_DT',\n",
       "   'TGR': 'a_DT boot_NN',\n",
       "   'Wrong_tag': 'TO',\n",
       "   'Wrong_word': 'to',\n",
       "   'pv': 'use_VB',\n",
       "   'pv_tag': 'VB'},\n",
       "  'from'),\n",
       " ({'BGL': 'diffract_VBN',\n",
       "   'BGR': 'the_DT',\n",
       "   'FH': 'surface_NN',\n",
       "   'FHtag': 'NN',\n",
       "   'FHword': 'surface',\n",
       "   'FP': 'the_DT surface_NN',\n",
       "   'PHR_pre': 'VP',\n",
       "   'TGL': 'be_VBD diffract_VBN',\n",
       "   'TGLR': 'diffract_VBN the_DT',\n",
       "   'TGR': 'the_DT surface_NN',\n",
       "   'Wrong_tag': 'IN',\n",
       "   'Wrong_word': 'from',\n",
       "   'pv': 'diffract_VBN',\n",
       "   'pv_tag': 'VBN'},\n",
       "  'at'),\n",
       " ({'BGL': 'part_NN',\n",
       "   'BGR': 'the_DT',\n",
       "   'FH': 'forthcoming_JJ',\n",
       "   'FHtag': 'JJ',\n",
       "   'FHword': 'forthcoming',\n",
       "   'FP': 'the_DT forthcoming_JJ',\n",
       "   'PHR_pre': 'NP',\n",
       "   'TGL': 'take_VB part_NN',\n",
       "   'TGLR': 'part_NN the_DT',\n",
       "   'TGR': 'the_DT forthcoming_JJ',\n",
       "   'Wrong_tag': 'IN',\n",
       "   'Wrong_word': 'at',\n",
       "   'pv': 'take_VB',\n",
       "   'pv_tag': 'VB'},\n",
       "  'in')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData= data_conversion(test_data,test_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.5418\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# train your classifier\n",
    "classifier = SklearnClassifier(LogisticRegression(C = 10))\n",
    "classifier.train(trainData)\n",
    "\n",
    "# test your classifier\n",
    "print \"accuracy: \",nltk.classify.accuracy(classifier, testData)\n",
    "\n",
    "correct = 0\n",
    "prediction = []\n",
    "answer = []\n",
    "for feature in testData:\n",
    "    prediction.append(classifier.classify(feature[0]))\n",
    "    answer.append(feature[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I tried logistic regression as a classifier and set C, which is inverse of regularization strength, to 10. It gave acuracy about 0.47 using _wiki.prep.sents.clean.genia.10k_ data and 0.54 in using _wiki.prep.sents.clean.genia.100k_ data.\n",
    "Then, I used *classification_report* function from scikit-learn. It could show f1-score for each category and the average f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     \"\"\"in\"       1.00      1.00      1.00        11\n",
      "     aboard       0.50      0.20      0.29         5\n",
      "      about       0.25      0.07      0.10        46\n",
      "      above       0.00      0.00      0.00         8\n",
      "     across       0.79      0.42      0.55        26\n",
      "      after       0.57      0.48      0.52       141\n",
      "    against       0.82      0.31      0.45        58\n",
      "     albeit       1.00      1.00      1.00         1\n",
      "      along       0.40      0.14      0.21        14\n",
      "  alongside       1.00      0.10      0.18        10\n",
      "   although       0.63      0.58      0.60        78\n",
      "       amid       0.00      0.00      0.00         2\n",
      "     amidst       0.00      0.00      0.00         1\n",
      "      among       0.62      0.56      0.59        41\n",
      "    amongst       0.80      0.33      0.47        12\n",
      "     around       0.64      0.26      0.37        34\n",
      "         as       0.30      0.17      0.22       172\n",
      "         at       0.41      0.31      0.35       382\n",
      "    because       0.13      0.05      0.07        44\n",
      "     before       0.44      0.13      0.20        31\n",
      "     behind       0.00      0.00      0.00         9\n",
      "      below       0.00      0.00      0.00         6\n",
      "    beneath       0.00      0.00      0.00         6\n",
      "     beside       0.00      0.00      0.00         3\n",
      "    besides       0.00      0.00      0.00         1\n",
      "    between       0.57      0.21      0.31        76\n",
      "     beyond       0.00      0.00      0.00         6\n",
      "         by       0.35      0.18      0.24       296\n",
      "         de       0.00      0.00      0.00         1\n",
      "    despite       0.00      0.00      0.00         6\n",
      "       down       0.00      0.00      0.00         3\n",
      "     during       0.28      0.23      0.25       176\n",
      "         en       1.00      0.33      0.50         3\n",
      "         fo       0.00      0.00      0.00         1\n",
      "        for       0.42      0.33      0.37       462\n",
      "       from       0.40      0.24      0.30       341\n",
      "         if       0.00      0.00      0.00         8\n",
      "         in       0.45      0.58      0.51      1121\n",
      "     inside       1.00      0.17      0.29         6\n",
      "       into       0.42      0.33      0.37       122\n",
      "       like       0.50      0.06      0.10        18\n",
      "       near       0.33      0.04      0.07        53\n",
      "       null       0.65      0.88      0.75      3365\n",
      "          o       0.00      0.00      0.00         1\n",
      "         of       0.42      0.52      0.46       645\n",
      "        off       1.00      0.11      0.20        18\n",
      "         on       0.55      0.55      0.55       684\n",
      "       once       0.00      0.00      0.00         1\n",
      "       onto       0.33      0.06      0.10        17\n",
      "        out       0.00      0.00      0.00         2\n",
      "    outside       1.00      0.17      0.29         6\n",
      "       over       0.21      0.09      0.12        46\n",
      "       past       0.00      0.00      0.00         1\n",
      "        per       0.00      0.00      0.00         2\n",
      "      since       0.41      0.13      0.20        82\n",
      "         so       0.00      0.00      0.00         3\n",
      "       than       0.89      0.20      0.32        41\n",
      "       that       0.10      0.03      0.05        33\n",
      "     though       0.17      0.04      0.06        25\n",
      "    through       0.49      0.29      0.36        97\n",
      " throughout       0.64      0.44      0.52        62\n",
      "       till       0.00      0.00      0.00         3\n",
      "         to       0.37      0.28      0.32       376\n",
      "     togsdf       0.00      0.00      0.00         1\n",
      "     toward       0.56      0.39      0.46        23\n",
      "    towards       0.47      0.33      0.39        24\n",
      "      under       0.57      0.09      0.16        43\n",
      " underneath       0.00      0.00      0.00         1\n",
      "     unless       0.00      0.00      0.00         2\n",
      "     unlike       0.50      0.25      0.33         4\n",
      "      until       0.83      0.56      0.67        71\n",
      "         up       0.00      0.00      0.00         5\n",
      "       upon       0.67      0.29      0.40        28\n",
      "        via       0.00      0.00      0.00        13\n",
      "    whereas       0.00      0.00      0.00         9\n",
      "    whether       0.78      0.58      0.67        12\n",
      "      while       0.84      0.41      0.55        51\n",
      "     whilst       0.00      0.00      0.00         6\n",
      "       with       0.37      0.26      0.30       298\n",
      "     within       0.17      0.08      0.11        53\n",
      "    without       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.51      0.54      0.51     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "# np.set_printoptions(threshold=np.nan)\n",
    "print classification_report(answer, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the above table, there're lots of **null** answer in the dataset and the word **to** has lower precision and recall.\n",
    "\n",
    "I also try other classification algorithms like **randomforest** and **svm**. After tuning the hyper-parameter, I thought the **logistic regression** should be a better choice. The F1-score is about 0.51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        'on       0.00      0.00      0.00         1\n",
      "      After       0.67      0.67      0.67         3\n",
      "   Although       0.67      0.50      0.57         4\n",
      "      Among       0.00      0.00      0.00         2\n",
      "         As       0.00      0.00      0.00         4\n",
      "         At       0.20      0.50      0.29         2\n",
      "    Because       0.00      0.00      0.00         2\n",
      "         By       0.00      0.00      0.00         5\n",
      "    Despite       0.00      0.00      0.00         2\n",
      "     During       0.20      1.00      0.33         2\n",
      "        For       0.00      0.00      0.00         2\n",
      "       From       0.00      0.00      0.00         3\n",
      "         In       0.24      0.64      0.35        11\n",
      "       NULL       0.62      0.66      0.64       333\n",
      "         On       0.62      0.62      0.62         8\n",
      "      Since       0.33      0.20      0.25         5\n",
      "     Though       0.00      0.00      0.00         0\n",
      " Throughout       0.00      0.00      0.00         1\n",
      "     Unlike       0.00      0.00      0.00         1\n",
      "     Within       0.00      0.00      0.00         1\n",
      "     aboard       0.00      0.00      0.00         1\n",
      "      about       0.00      0.00      0.00         3\n",
      "      above       0.00      0.00      0.00         1\n",
      "     across       1.00      0.20      0.33         5\n",
      "      after       0.50      0.17      0.25         6\n",
      "    against       0.00      0.00      0.00         6\n",
      "      along       0.00      0.00      0.00         1\n",
      "  alongside       0.00      0.00      0.00         0\n",
      "   although       0.50      0.50      0.50         8\n",
      "      among       0.10      0.33      0.15         3\n",
      "    amongst       0.00      0.00      0.00         3\n",
      "     around       0.00      0.00      0.00         1\n",
      "         as       0.00      0.00      0.00        11\n",
      "         at       0.15      0.11      0.13        27\n",
      "    because       0.33      0.25      0.29         4\n",
      "     before       0.20      1.00      0.33         1\n",
      "      below       0.00      0.00      0.00         1\n",
      "    beneath       0.00      0.00      0.00         1\n",
      "    between       0.50      0.18      0.27        11\n",
      "         by       0.32      0.19      0.24        31\n",
      "     during       0.06      0.10      0.07        10\n",
      "        for       0.19      0.08      0.11        52\n",
      "       from       0.37      0.23      0.29        30\n",
      "         if       0.00      0.00      0.00         2\n",
      "         in       0.30      0.47      0.37        98\n",
      "     inside       0.00      0.00      0.00         2\n",
      "       into       0.10      0.20      0.13        10\n",
      "       like       0.00      0.00      0.00         2\n",
      "       near       0.00      0.00      0.00         5\n",
      "         of       0.25      0.42      0.31        62\n",
      "        off       0.00      0.00      0.00         1\n",
      "         on       0.38      0.31      0.34        71\n",
      "       onto       0.00      0.00      0.00         2\n",
      "       over       0.00      0.00      0.00         2\n",
      "       past       0.00      0.00      0.00         2\n",
      "      since       0.00      0.00      0.00         7\n",
      "       than       0.33      1.00      0.50         1\n",
      "       that       0.00      0.00      0.00         7\n",
      "     though       0.00      0.00      0.00         1\n",
      "    through       0.33      0.30      0.32        10\n",
      " throughout       0.75      0.60      0.67         5\n",
      "       till       0.00      0.00      0.00         1\n",
      "         to       0.22      0.17      0.19        40\n",
      "     toward       0.80      1.00      0.89         4\n",
      "    towards       0.00      0.00      0.00         1\n",
      "      under       0.00      0.00      0.00         3\n",
      " underneath       0.00      0.00      0.00         0\n",
      "      until       0.50      0.42      0.45        12\n",
      "       upon       0.00      0.00      0.00         2\n",
      "     versus       0.00      0.00      0.00         1\n",
      "        via       0.00      0.00      0.00         1\n",
      "    whether       0.50      1.00      0.67         1\n",
      "      while       0.75      0.43      0.55         7\n",
      "       with       0.00      0.00      0.00        22\n",
      "     within       0.00      0.00      0.00         5\n",
      "    without       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.38      0.40      0.38      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = SklearnClassifier(RandomForestClassifier(n_estimators=50,max_features=None,class_weight=\"balanced\"))\n",
    "rf.train(trainData)\n",
    "\n",
    "# test your classifier\n",
    "print \"accuracy: \",nltk.classify.accuracy(rf, testData)\n",
    "correct = 0\n",
    "prediction = []\n",
    "answer = []\n",
    "for feature in testData:\n",
    "    prediction.append(rf.classify(feature[0]))\n",
    "    answer.append(feature[1])\n",
    "    if feature[0]==feature[1]:\n",
    "        correct += 1\n",
    "print classification_report(answer, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        'on       0.00      0.00      0.00         1\n",
      "      After       0.00      0.00      0.00         3\n",
      "   Although       0.00      0.00      0.00         4\n",
      "      Among       0.00      0.00      0.00         2\n",
      "         As       0.00      0.00      0.00         4\n",
      "         At       0.00      0.00      0.00         2\n",
      "    Because       0.00      0.00      0.00         2\n",
      "         By       0.00      0.00      0.00         5\n",
      "    Despite       0.00      0.00      0.00         2\n",
      "     During       0.00      0.00      0.00         2\n",
      "        For       0.00      0.00      0.00         2\n",
      "       From       0.00      0.00      0.00         3\n",
      "         In       0.10      0.27      0.14        11\n",
      "       NULL       0.49      0.69      0.57       333\n",
      "         On       0.33      0.50      0.40         8\n",
      "      Since       0.00      0.00      0.00         5\n",
      " Throughout       0.00      0.00      0.00         1\n",
      "     Unlike       0.00      0.00      0.00         1\n",
      "     Within       0.00      0.00      0.00         1\n",
      "     aboard       0.00      0.00      0.00         1\n",
      "      about       0.00      0.00      0.00         3\n",
      "      above       0.00      0.00      0.00         1\n",
      "     across       0.00      0.00      0.00         5\n",
      "      after       0.00      0.00      0.00         6\n",
      "    against       0.00      0.00      0.00         6\n",
      "      along       0.00      0.00      0.00         1\n",
      "   although       0.29      0.62      0.40         8\n",
      "      among       0.00      0.00      0.00         3\n",
      "    amongst       0.00      0.00      0.00         3\n",
      "     around       0.00      0.00      0.00         1\n",
      "         as       0.00      0.00      0.00        11\n",
      "         at       0.18      0.07      0.11        27\n",
      "    because       0.00      0.00      0.00         4\n",
      "     before       0.00      0.00      0.00         1\n",
      "      below       0.00      0.00      0.00         1\n",
      "    beneath       0.00      0.00      0.00         1\n",
      "    between       0.17      0.09      0.12        11\n",
      "         by       0.09      0.06      0.07        31\n",
      "     during       0.00      0.00      0.00        10\n",
      "        for       0.00      0.00      0.00        52\n",
      "       from       0.15      0.07      0.09        30\n",
      "         if       0.00      0.00      0.00         2\n",
      "         in       0.12      0.13      0.12        98\n",
      "     inside       0.00      0.00      0.00         2\n",
      "       into       0.00      0.00      0.00        10\n",
      "       like       0.00      0.00      0.00         2\n",
      "       near       0.00      0.00      0.00         5\n",
      "         of       0.14      0.32      0.19        62\n",
      "        off       0.00      0.00      0.00         1\n",
      "         on       0.34      0.28      0.31        71\n",
      "       onto       0.00      0.00      0.00         2\n",
      "       over       0.00      0.00      0.00         2\n",
      "       past       0.00      0.00      0.00         2\n",
      "      since       0.00      0.00      0.00         7\n",
      "       than       0.06      1.00      0.11         1\n",
      "       that       0.00      0.00      0.00         7\n",
      "     though       0.00      0.00      0.00         1\n",
      "    through       0.00      0.00      0.00        10\n",
      " throughout       0.00      0.00      0.00         5\n",
      "       till       0.00      0.00      0.00         1\n",
      "         to       0.00      0.00      0.00        40\n",
      "     toward       0.00      0.00      0.00         4\n",
      "    towards       0.00      0.00      0.00         1\n",
      "      under       0.00      0.00      0.00         3\n",
      "      until       0.00      0.00      0.00        12\n",
      "       upon       0.00      0.00      0.00         2\n",
      "     versus       0.00      0.00      0.00         1\n",
      "        via       0.00      0.00      0.00         1\n",
      "    whether       0.00      0.00      0.00         1\n",
      "      while       0.00      0.00      0.00         7\n",
      "       with       0.00      0.00      0.00        22\n",
      "     within       0.00      0.00      0.00         5\n",
      "    without       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.23      0.30      0.25      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.01,0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "svm = SklearnClassifier(GridSearchCV(SVC(),param_grid))\n",
    "svm.train(trainData)\n",
    "\n",
    "# test your classifier\n",
    "print \"accuracy: \",nltk.classify.accuracy(svm, testData)\n",
    "correct = 0\n",
    "prediction = []\n",
    "answer = []\n",
    "for feature in testData:\n",
    "    prediction.append(rf.classify(feature[0]))\n",
    "    answer.append(feature[1])\n",
    "    if feature[0]==feature[1]:\n",
    "        correct += 1\n",
    "print classification_report(answer, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
