{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import jieba.analyse\n",
    "import jieba\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data/chat_0003e590ac9f414a51c1245bc02f17eb.csv', 'C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data/chat_000403321513e40db8000af807ec7f96.csv', 'C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data/chat_00067296c7b74fec845c2368964f430c.csv']\n",
      "['chat_0003e590ac9f414a51c1245bc02f17eb.csv', 'chat_000403321513e40db8000af807ec7f96.csv', 'chat_00067296c7b74fec845c2368964f430c.csv']\n"
     ]
    }
   ],
   "source": [
    "folder_dir = \"C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data\"\n",
    "file_path = [ folder_dir +\"/\"+ path for path in listdir(folder_dir) ]\n",
    "file_name = listdir(folder_dir)\n",
    "print file_path[:3]\n",
    "print file_name[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receiver</th>\n",
       "      <th>sender</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>sender_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>Hello..妳好...I am Thomas...希望有機會與妳聊聊...更希望彼此是彼此...</td>\n",
       "      <td>1464245603</td>\n",
       "      <td>7</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>希望有機會與Sake聊聊</td>\n",
       "      <td>1464245617</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>嗯嗯 我在上班 下班晚點可以聊聊</td>\n",
       "      <td>1464245695</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>^_^</td>\n",
       "      <td>1464245696</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>好的</td>\n",
       "      <td>1464245716</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>哈 謝謝</td>\n",
       "      <td>1464245746</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>😊</td>\n",
       "      <td>1464245761</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>妳先忙工作</td>\n",
       "      <td>1464245771</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>嗯嗯好 你也是</td>\n",
       "      <td>1464245872</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>下班了嗎？</td>\n",
       "      <td>1464261204</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>Sake喜愛吃什麼美食呢？</td>\n",
       "      <td>1464272651</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>下班了</td>\n",
       "      <td>1464272759</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>在看武媚娘</td>\n",
       "      <td>1464272771</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>呵呵</td>\n",
       "      <td>1464272776</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>我都可以</td>\n",
       "      <td>1464272782</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>什麼美食都愛吃</td>\n",
       "      <td>1464272796</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>我只剩吃的功能了</td>\n",
       "      <td>1464272806</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>武媚娘不是過時了嗎？哈哈</td>\n",
       "      <td>1464272809</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>哈</td>\n",
       "      <td>1464272812</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0003e590ac9f414a51c1245bc02f17eb</td>\n",
       "      <td>0b39d793a34f41903319898f24737bc8</td>\n",
       "      <td>謙虛了</td>\n",
       "      <td>1464272815</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            receiver                            sender  \\\n",
       "0   0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "1   0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "2   0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "3   0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "4   0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "5   0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "6   0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "7   0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "8   0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "9   0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "10  0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "11  0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "12  0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "13  0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "14  0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "15  0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "16  0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "17  0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "18  0b39d793a34f41903319898f24737bc8  0003e590ac9f414a51c1245bc02f17eb   \n",
       "19  0003e590ac9f414a51c1245bc02f17eb  0b39d793a34f41903319898f24737bc8   \n",
       "\n",
       "                                                 text        time  type  \\\n",
       "0   Hello..妳好...I am Thomas...希望有機會與妳聊聊...更希望彼此是彼此...  1464245603     7   \n",
       "1                                        希望有機會與Sake聊聊  1464245617     0   \n",
       "2                                    嗯嗯 我在上班 下班晚點可以聊聊  1464245695     0   \n",
       "3                                                 ^_^  1464245696     0   \n",
       "4                                                  好的  1464245716     0   \n",
       "5                                                哈 謝謝  1464245746     0   \n",
       "6                                                  😊  1464245761     0   \n",
       "7                                               妳先忙工作  1464245771     0   \n",
       "8                                             嗯嗯好 你也是  1464245872     0   \n",
       "9                                               下班了嗎？  1464261204     0   \n",
       "10                                      Sake喜愛吃什麼美食呢？  1464272651     0   \n",
       "11                                                下班了  1464272759     0   \n",
       "12                                              在看武媚娘  1464272771     0   \n",
       "13                                                 呵呵  1464272776     0   \n",
       "14                                               我都可以  1464272782     0   \n",
       "15                                            什麼美食都愛吃  1464272796     0   \n",
       "16                                           我只剩吃的功能了  1464272806     0   \n",
       "17                                       武媚娘不是過時了嗎？哈哈  1464272809     0   \n",
       "18                                                  哈  1464272812     0   \n",
       "19                                                謙虛了  1464272815     0   \n",
       "\n",
       "   sender_gender  \n",
       "0              m  \n",
       "1              m  \n",
       "2              f  \n",
       "3              f  \n",
       "4              m  \n",
       "5              f  \n",
       "6              m  \n",
       "7              m  \n",
       "8              f  \n",
       "9              m  \n",
       "10             m  \n",
       "11             f  \n",
       "12             f  \n",
       "13             f  \n",
       "14             f  \n",
       "15             f  \n",
       "16             f  \n",
       "17             m  \n",
       "18             f  \n",
       "19             m  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_frame = pd.read_csv(file_path[0])\n",
    "chat_frame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😊\n"
     ]
    }
   ],
   "source": [
    "print chat_frame.loc[6,\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep emoji (extract emoji element previously, then cut the words, finally append the emoji back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#build emoji dictionary\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "emoji_list = []\n",
    "url = \"https://apps.timwhitlock.info/emoji/tables/unicode\"\n",
    "r = requests.get(url).content\n",
    "soup = BeautifulSoup(r)\n",
    "for ele in soup.find_all(\"td\", class_=\"code\"):\n",
    "    emo_ele = ele.text\n",
    "    if emo_ele.startswith(\"\\\\\"):\n",
    "        emoji_list.append(emo_ele.decode(\"utf8\").decode('string_escape')) #remove redundant backslash for latter matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_frame.loc[6,\"text\"] in emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xf0\\x9f\\x98\\x82'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write emoji character into jieba dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😊\n",
      "Emoji \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = chat_frame.loc[6,\"text\"]\n",
    "print text\n",
    "def emoji_extractor(text):\n",
    "    text = text.decode(\"utf8\")\n",
    "    try:\n",
    "        # UCS-4\n",
    "        highpoints = re.compile(u'[\\U00010000-\\U0010ffff]')\n",
    "    except re.error:\n",
    "        # UCS-2\n",
    "        highpoints = re.compile(u'[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]')\n",
    "    return highpoints.sub(\"Emoji \", text)\n",
    "print emoji_extractor(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#customize dictionary\n",
    "jieba.set_dictionary('C:\\\\Python27\\\\Lib\\\\site-packages\\\\jieba\\\\dict.txt.big.txt')\n",
    "jieba.analyse.set_stop_words(\"C:\\\\Python27\\\\Lib\\\\site-packages\\\\jieba\\\\stop_words.txt\")\n",
    "jieba.analyse.set_idf_path(\"C:\\\\Python27\\\\Lib\\\\site-packages\\\\jieba\\\\idf.txt.big.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Python27\\Lib\\site-packages\\jieba\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\tsunh\\appdata\\local\\temp\\jieba.u7ecb02fee068d7d39e5500de2047abc1.cache\n",
      "Loading model cost 0.668 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "for i in range(chat_frame.shape[0]):\n",
    "    text = chat_frame.loc[i,\"text\"]\n",
    "    text_ele = emoji_extractor(text)\n",
    "    chat_frame.loc[i,\"seg_text\"] = \" \".join(jieba.cut(text_ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoji  \n"
     ]
    }
   ],
   "source": [
    "print chat_frame[\"seg_text\"][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch word segment and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19632\n"
     ]
    }
   ],
   "source": [
    "seg_folder_dir = \"C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data_seg/\"\n",
    "seg_path = [ seg_folder_dir +\"/\"+ path for path in listdir(seg_folder_dir) ]\n",
    "seg_name = listdir(seg_folder_dir)\n",
    "\n",
    "folder_dir = \"C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data\"\n",
    "file_path = [ folder_dir +\"/\"+ path for path in listdir(folder_dir) if path not in seg_name ]\n",
    "file_name = [i for i in listdir(folder_dir) if i not in seg_name]\n",
    "print len(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19632\n"
     ]
    }
   ],
   "source": [
    "print len(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for path, name in zip(file_path,file_name):\n",
    "    chat_frame = pd.read_csv(path)\n",
    "    for row in range(chat_frame.shape[0]):\n",
    "        text = chat_frame.loc[row,\"text\"]\n",
    "        try:\n",
    "            text_ele = emoji_extractor(text)\n",
    "            chat_frame.loc[row,\"seg_text\"] = \" \".join(jieba.cut(text_ele))\n",
    "        except:\n",
    "            chat_frame.loc[row,\"seg_text\"] = \" \"\n",
    "    chat_frame.to_csv(\"C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data_seg/\"+name,\n",
    "                      index = False,\n",
    "                     encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load chinese word2vec model\n",
    "word2vec = pd.read_csv(\"c:/Users/tsunh/Desktop/Schoolwork/NLPlab/wiki_wordvector_utf8.csv\",index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V91</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gobies</th>\n",
       "      <td>-0.640565</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.413354</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.401215</td>\n",
       "      <td>-0.072820</td>\n",
       "      <td>-0.295357</td>\n",
       "      <td>1.005226</td>\n",
       "      <td>-0.186935</td>\n",
       "      <td>0.215594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196001</td>\n",
       "      <td>-0.294534</td>\n",
       "      <td>-0.734109</td>\n",
       "      <td>0.079843</td>\n",
       "      <td>0.706463</td>\n",
       "      <td>-0.475461</td>\n",
       "      <td>-0.280217</td>\n",
       "      <td>-0.067575</td>\n",
       "      <td>-0.103508</td>\n",
       "      <td>0.071767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gorsuch</th>\n",
       "      <td>-0.267785</td>\n",
       "      <td>0.249702</td>\n",
       "      <td>-0.087891</td>\n",
       "      <td>-0.568892</td>\n",
       "      <td>0.344263</td>\n",
       "      <td>-0.252007</td>\n",
       "      <td>-0.730565</td>\n",
       "      <td>0.439203</td>\n",
       "      <td>0.282937</td>\n",
       "      <td>-0.585860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949666</td>\n",
       "      <td>-0.311173</td>\n",
       "      <td>-0.281239</td>\n",
       "      <td>0.430901</td>\n",
       "      <td>0.382697</td>\n",
       "      <td>-0.381894</td>\n",
       "      <td>0.151197</td>\n",
       "      <td>0.962285</td>\n",
       "      <td>-0.618023</td>\n",
       "      <td>0.688148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>由奧恰</th>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.175031</td>\n",
       "      <td>-0.574771</td>\n",
       "      <td>0.530207</td>\n",
       "      <td>0.146367</td>\n",
       "      <td>-0.002879</td>\n",
       "      <td>-0.008207</td>\n",
       "      <td>-0.573806</td>\n",
       "      <td>0.449668</td>\n",
       "      <td>0.985068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393548</td>\n",
       "      <td>-0.425076</td>\n",
       "      <td>0.473486</td>\n",
       "      <td>-0.124235</td>\n",
       "      <td>0.068624</td>\n",
       "      <td>0.631609</td>\n",
       "      <td>0.641269</td>\n",
       "      <td>-0.575997</td>\n",
       "      <td>-0.397369</td>\n",
       "      <td>-0.693963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>朝義著</th>\n",
       "      <td>-0.425897</td>\n",
       "      <td>-0.019429</td>\n",
       "      <td>-0.340932</td>\n",
       "      <td>0.088261</td>\n",
       "      <td>-0.585137</td>\n",
       "      <td>-0.280552</td>\n",
       "      <td>0.031831</td>\n",
       "      <td>-0.265396</td>\n",
       "      <td>-0.211374</td>\n",
       "      <td>-0.132702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059611</td>\n",
       "      <td>-0.648249</td>\n",
       "      <td>-0.707557</td>\n",
       "      <td>0.224414</td>\n",
       "      <td>0.688562</td>\n",
       "      <td>0.134534</td>\n",
       "      <td>-0.808125</td>\n",
       "      <td>0.879801</td>\n",
       "      <td>-0.356066</td>\n",
       "      <td>0.401297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calabai</th>\n",
       "      <td>0.295467</td>\n",
       "      <td>-0.605804</td>\n",
       "      <td>0.100886</td>\n",
       "      <td>0.134296</td>\n",
       "      <td>-0.275335</td>\n",
       "      <td>-0.487929</td>\n",
       "      <td>-0.092787</td>\n",
       "      <td>-0.483964</td>\n",
       "      <td>-0.285548</td>\n",
       "      <td>-0.504646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853770</td>\n",
       "      <td>0.038695</td>\n",
       "      <td>0.309583</td>\n",
       "      <td>0.751271</td>\n",
       "      <td>-0.084114</td>\n",
       "      <td>-0.082777</td>\n",
       "      <td>0.148701</td>\n",
       "      <td>0.175883</td>\n",
       "      <td>0.858911</td>\n",
       "      <td>-0.589927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1        V2        V3        V4        V5        V6        V7  \\\n",
       "gobies  -0.640565  0.033635  0.413354  0.001317  0.401215 -0.072820 -0.295357   \n",
       "Gorsuch -0.267785  0.249702 -0.087891 -0.568892  0.344263 -0.252007 -0.730565   \n",
       "由奧恰      0.010707  0.175031 -0.574771  0.530207  0.146367 -0.002879 -0.008207   \n",
       "朝義著     -0.425897 -0.019429 -0.340932  0.088261 -0.585137 -0.280552  0.031831   \n",
       "calabai  0.295467 -0.605804  0.100886  0.134296 -0.275335 -0.487929 -0.092787   \n",
       "\n",
       "               V8        V9       V10    ...          V91       V92       V93  \\\n",
       "gobies   1.005226 -0.186935  0.215594    ...     0.196001 -0.294534 -0.734109   \n",
       "Gorsuch  0.439203  0.282937 -0.585860    ...     0.949666 -0.311173 -0.281239   \n",
       "由奧恰     -0.573806  0.449668  0.985068    ...     0.393548 -0.425076  0.473486   \n",
       "朝義著     -0.265396 -0.211374 -0.132702    ...    -0.059611 -0.648249 -0.707557   \n",
       "calabai -0.483964 -0.285548 -0.504646    ...     0.853770  0.038695  0.309583   \n",
       "\n",
       "              V94       V95       V96       V97       V98       V99      V100  \n",
       "gobies   0.079843  0.706463 -0.475461 -0.280217 -0.067575 -0.103508  0.071767  \n",
       "Gorsuch  0.430901  0.382697 -0.381894  0.151197  0.962285 -0.618023  0.688148  \n",
       "由奧恰     -0.124235  0.068624  0.631609  0.641269 -0.575997 -0.397369 -0.693963  \n",
       "朝義著      0.224414  0.688562  0.134534 -0.808125  0.879801 -0.356066  0.401297  \n",
       "calabai  0.751271 -0.084114 -0.082777  0.148701  0.175883  0.858911 -0.589927  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268569, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69812921]]\n",
      "[[ 0.52460531]]\n",
      "[[ 0.67427972]]\n"
     ]
    }
   ],
   "source": [
    "def vector_sim(x,y):\n",
    "    return cosine_similarity(np.array(x).reshape(1,-1),np.array(y).reshape(1,-1))\n",
    "print vector_sim(word2vec.loc[\"新竹\"],word2vec.loc[\"桃園\"])\n",
    "print vector_sim(word2vec.loc[\"雲林\"],word2vec.loc[\"桃園\"])\n",
    "print vector_sim(word2vec.loc[\"雲林\"],word2vec.loc[\"嘉義\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### document represented by word2vec average (median) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_folder_dir = \"C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data_seg/\"\n",
    "seg_path = [ seg_folder_dir +\"/\"+ path for path in listdir(seg_folder_dir) ]\n",
    "seg_name = listdir(seg_folder_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receiver</th>\n",
       "      <th>sender</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>sender_gender</th>\n",
       "      <th>seg_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000403321513e40db8000af807ec7f96</td>\n",
       "      <td>42132af3ebc9a36017752a0d67d5e09d</td>\n",
       "      <td>嗨！ 妳好阿</td>\n",
       "      <td>1444407467</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>嗨 ！   妳 好 阿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42132af3ebc9a36017752a0d67d5e09d</td>\n",
       "      <td>000403321513e40db8000af807ec7f96</td>\n",
       "      <td>嗨~</td>\n",
       "      <td>1444437791</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>嗨 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000403321513e40db8000af807ec7f96</td>\n",
       "      <td>42132af3ebc9a36017752a0d67d5e09d</td>\n",
       "      <td>休假沒有出去玩</td>\n",
       "      <td>1444448624</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>休假 沒有 出去玩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000403321513e40db8000af807ec7f96</td>\n",
       "      <td>42132af3ebc9a36017752a0d67d5e09d</td>\n",
       "      <td>妳因該很少來甜甜圈這裡吧</td>\n",
       "      <td>1444448698</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>妳 因該 很少 來 甜甜 圈 這裡 吧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42132af3ebc9a36017752a0d67d5e09d</td>\n",
       "      <td>000403321513e40db8000af807ec7f96</td>\n",
       "      <td>我昨天晚上才下載看看的！哈哈</td>\n",
       "      <td>1444455165</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>我 昨天晚上 才 下載 看看 的 ！ 哈哈</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           receiver                            sender  \\\n",
       "0  000403321513e40db8000af807ec7f96  42132af3ebc9a36017752a0d67d5e09d   \n",
       "1  42132af3ebc9a36017752a0d67d5e09d  000403321513e40db8000af807ec7f96   \n",
       "2  000403321513e40db8000af807ec7f96  42132af3ebc9a36017752a0d67d5e09d   \n",
       "3  000403321513e40db8000af807ec7f96  42132af3ebc9a36017752a0d67d5e09d   \n",
       "4  42132af3ebc9a36017752a0d67d5e09d  000403321513e40db8000af807ec7f96   \n",
       "\n",
       "             text        time  type sender_gender               seg_text  \n",
       "0          嗨！ 妳好阿  1444407467     0             m            嗨 ！   妳 好 阿  \n",
       "1              嗨~  1444437791     0             f                    嗨 ~  \n",
       "2         休假沒有出去玩  1444448624     0             m              休假 沒有 出去玩  \n",
       "3    妳因該很少來甜甜圈這裡吧  1444448698     0             m    妳 因該 很少 來 甜甜 圈 這裡 吧  \n",
       "4  我昨天晚上才下載看看的！哈哈  1444455165     0             f  我 昨天晚上 才 下載 看看 的 ！ 哈哈  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(seg_path[1])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_d2v_file(path,name):\n",
    "    column_name = [\"v\"+str(i) for i in range(1,101)]\n",
    "    df = pd.read_csv(path)\n",
    "    vec_frame = []\n",
    "    for row in range(df.shape[0]):\n",
    "        word2vec2doc = []\n",
    "        \n",
    "        for word in df.loc[row,\"seg_text\"].split(\" \"):\n",
    "                try:\n",
    "                    word2vec2doc.append(np.array(word2vec.loc[word]))\n",
    "                except:\n",
    "                    word2vec2doc.append(np.zeros(100))\n",
    "                    \n",
    "        vec_frame.append(np.mean(np.array(word2vec2doc),axis = 0))\n",
    "    frame_with_DocVec = pd.concat([df, pd.DataFrame(np.array(vec_frame),columns=column_name)], axis=1)\n",
    "    frame_with_DocVec.to_csv(\"C:/Users/tsunh/Desktop/Schoolwork/NLPlab/sr_chat_data/sr_chat_data_DV/\"+name,\n",
    "                          index = False,\n",
    "                         encoding=\"utf8\")\n",
    "    \n",
    "# for path, name in zip(seg_path,seg_name):\n",
    "#     create_d2v_file(path,name)\n",
    "Parallel(n_jobs=2)(delayed(create_d2v_file)(path,name) for path, name in zip(seg_path,seg_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗨\n",
      "！\n",
      "\n",
      "\n",
      "妳\n",
      "好\n",
      "阿\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01265901, -0.28645023, -0.12414637,  0.15532378,  0.06675993,\n",
       "        0.21572613,  0.01586927,  0.01928163, -0.16977498,  0.49181543,\n",
       "       -0.18359625,  0.21302659, -0.21054676, -0.10143435,  0.36809709,\n",
       "       -0.11277422,  0.07332392, -0.34659433,  0.25986605,  0.06379166,\n",
       "        0.50997516, -0.12019864, -0.23410239,  0.22958985, -0.2011734 ,\n",
       "        0.02703978,  0.36428104, -0.19721388,  0.14094882, -0.35433115,\n",
       "        0.74377856,  0.28540112, -0.19547316,  0.21906016,  0.06786173,\n",
       "       -0.03714963, -0.26161875,  0.20787675, -0.13378314,  0.43746244,\n",
       "        0.02895689,  0.07127717,  0.49596735,  0.06672881, -0.37759267,\n",
       "        0.1423058 , -0.15724532, -0.42832666, -0.48626658, -0.25020022,\n",
       "       -0.31862739, -0.17347516, -0.00472732,  0.38206937,  0.09703728,\n",
       "        0.20031133, -0.00076469, -0.71390074,  0.00878887, -0.15457282,\n",
       "       -0.18275521,  0.05956632,  0.14006899,  0.15386101,  0.0885594 ,\n",
       "        0.11892621,  0.14480148,  0.1052328 , -0.21038257, -0.1611297 ,\n",
       "        0.35057024, -0.27475471, -0.52574292, -0.17144647,  0.03734664,\n",
       "       -0.42952571,  0.11614229,  0.12517603,  0.20622772, -0.16446712,\n",
       "        0.31181308,  0.01917871, -0.24595599,  0.41598291, -0.10773963,\n",
       "       -0.06120528, -0.40612632,  0.07597303,  0.20958941,  0.13983095,\n",
       "       -0.18278768,  0.13223002, -0.19604626,  0.07183358,  0.04915047,\n",
       "        0.21239659, -0.10005767, -0.13238058,  0.07388454, -0.12323875])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec2doc = []\n",
    "for word in test_df.loc[0,\"seg_text\"].split(\" \"):\n",
    "    print word\n",
    "    try:\n",
    "        word2vec2doc.append(np.array(word2vec.loc[word]))\n",
    "    except:\n",
    "        word2vec2doc.append(np.zeros(100))\n",
    "\n",
    "np.mean(np.array(word2vec2doc),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
